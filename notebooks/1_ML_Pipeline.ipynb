{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFUfVoFNPiE8"
      },
      "source": [
        "## **Spaceship Titanic Classification with Decision Tree/ Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ranu-lrSP5KT"
      },
      "source": [
        "# **1. Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVcfRwF7P4PK",
        "outputId": "60e14052-b1d5-4a4b-bf03-343f570f32da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading spaceship-titanic.zip to /content\n",
            "\r  0% 0.00/299k [00:00<?, ?B/s]\n",
            "\r100% 299k/299k [00:00<00:00, 53.7MB/s]\n",
            "Archive:  spaceship-titanic.zip\n",
            "  inflating: dataset/sample_submission.csv  \n",
            "  inflating: dataset/test.csv        \n",
            "  inflating: dataset/train.csv       \n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "kaggle_token = {\"username\":\"thinhvan\",\"key\":\"a7b33f792a3ea40881d8be4db4014871\"}\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_token, f)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c spaceship-titanic\n",
        "!unzip spaceship-titanic.zip -d dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf5ANR94VExF"
      },
      "source": [
        "# **2. Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9kq-UYr1VBbU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "try:\n",
        "  from xgboost import XGBClassifier\n",
        "except:\n",
        "  !pip install xgboost\n",
        "  from xgboost import XGBClassifier\n",
        "\n",
        "# ============================\n",
        "# 1. Load dataset\n",
        "# ============================\n",
        "train_df = pd.read_csv(\"dataset/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_-R30OblXGrk"
      },
      "outputs": [],
      "source": [
        "# ============================\n",
        "# 2. Preprocessing\n",
        "# ============================\n",
        "\n",
        "# Split <PassengerID> in to <Group> and <Member>\n",
        "train_df[[\"Group\", \"Member\"]] = train_df[\"PassengerId\"].str.split(\"_\", expand=True)\n",
        "\n",
        "# Split Cabin into <Deck>, <Num> and <Side> features\n",
        "train_df[[\"Deck\", \"Num\", \"Side\"]] = train_df[\"Cabin\"].str.split(\"/\", expand=True)\n",
        "\n",
        "# Convert <Num>, <Group> to numeric type\n",
        "train_df[\"Group\"] = train_df[\"Group\"].astype(\"float\")\n",
        "train_df[\"Num\"] = train_df[\"Num\"].astype(\"float\")\n",
        "\n",
        "# Eliminate unvaluable and redundant attribute: <Name>, <Cabin>, <PassengerId>\n",
        "train_df = train_df.drop(columns=[\"Name\", \"Cabin\", \"PassengerId\"])\n",
        "\n",
        "# Missing data\n",
        "numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', \"Num\", \"Group\"]\n",
        "categorical_features = ['Member', 'HomePlanet', 'CryoSleep', 'Deck', 'Side', 'Destination', 'VIP']\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Split dataset to train/test = 0.8/0.2\n",
        "X = train_df.drop(\"Transported\", axis=1)\n",
        "y = train_df[\"Transported\"].astype(\"int\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Fit preprocessing\n",
        "preprocessor.fit(X_train)\n",
        "\n",
        "X_train = preprocessor.transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VElu2EZCh_4D"
      },
      "source": [
        "# **3. Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YuRZwGWqh_GU"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# Setup models and hyperparameters\n",
        "# ======================\n",
        "\n",
        "# Models\n",
        "models = {\n",
        "  \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "  \"SVM (RBF Kernel)\": SVC(kernel=\"rbf\", probability=False, random_state=42),\n",
        "  \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "  \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "  \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "  \"XGBoost\": XGBClassifier(eval_metric=\"logloss\", random_state=42)\n",
        "}\n",
        "\n",
        "# PCA rates\n",
        "pca_components = [None, 0.95, 0.9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S66PIRFNf5T_",
        "outputId": "dac49dd2-4c78-468e-bcfc-0dadf8d0eb92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Training Logistic Regression - PCA@1.0\n",
            "[INFO] Training Logistic Regression - PCA@0.95\n",
            "[INFO] Training Logistic Regression - PCA@0.90\n",
            "[INFO] Training SVM (RBF Kernel) - PCA@1.0\n",
            "[INFO] Training SVM (RBF Kernel) - PCA@0.95\n",
            "[INFO] Training SVM (RBF Kernel) - PCA@0.90\n",
            "[INFO] Training Decision Tree - PCA@1.0\n",
            "[INFO] Training Decision Tree - PCA@0.95\n",
            "[INFO] Training Decision Tree - PCA@0.90\n",
            "[INFO] Training Random Forest - PCA@1.0\n",
            "[INFO] Training Random Forest - PCA@0.95\n",
            "[INFO] Training Random Forest - PCA@0.90\n",
            "[INFO] Training Gradient Boosting - PCA@1.0\n",
            "[INFO] Training Gradient Boosting - PCA@0.95\n",
            "[INFO] Training Gradient Boosting - PCA@0.90\n",
            "[INFO] Training XGBoost - PCA@1.0\n",
            "[INFO] Training XGBoost - PCA@0.95\n",
            "[INFO] Training XGBoost - PCA@0.90\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# Fit and tracking results\n",
        "# ======================\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "  for rate in pca_components:\n",
        "    pipe = Pipeline(steps=[\n",
        "        (\"pca\", PCA(n_components=rate, random_state=42)),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "    nc = \"{:.2f}\".format(rate) if rate is not None else str(1.00)\n",
        "    print(f\"[INFO] Training {name} - PCA@{nc}\")\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    results[name+f\" - PCA@{nc}\"] = {\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, average=\"weighted\"),\n",
        "        \"recall\": recall_score(y_test, y_pred, average=\"weighted\"),\n",
        "        \"f1\": f1_score(y_test, y_pred, average=\"weighted\")\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrmsyOvNmvko"
      },
      "source": [
        "## **4. Experriment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fujc8dgVms2w",
        "outputId": "a3052df5-3a03-455d-ee80-0483262e1b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                accuracy  precision    recall        f1\n",
            "Logistic Regression - PCA@1.0   0.787234   0.787324  0.787234  0.787195\n",
            "Logistic Regression - PCA@0.95  0.785509   0.785549  0.785509  0.785485\n",
            "Logistic Regression - PCA@0.90  0.781484   0.781549  0.781484  0.781450\n",
            "SVM (RBF Kernel) - PCA@1.0      0.797010   0.797124  0.797010  0.797008\n",
            "SVM (RBF Kernel) - PCA@0.95     0.791259   0.791291  0.791259  0.791262\n",
            "SVM (RBF Kernel) - PCA@0.90     0.789534   0.789539  0.789534  0.789536\n",
            "Decision Tree - PCA@1.0         0.736055   0.736065  0.736055  0.736058\n",
            "Decision Tree - PCA@0.95        0.733180   0.733498  0.733180  0.733024\n",
            "Decision Tree - PCA@0.90        0.722829   0.722867  0.722829  0.722787\n",
            "Random Forest - PCA@1.0         0.797010   0.797676  0.797010  0.796942\n",
            "Random Forest - PCA@0.95        0.798735   0.799506  0.798735  0.798654\n",
            "Random Forest - PCA@0.90        0.798735   0.799437  0.798735  0.798663\n",
            "Gradient Boosting - PCA@1.0     0.796435   0.797055  0.796435  0.796279\n",
            "Gradient Boosting - PCA@0.95    0.791259   0.791835  0.791259  0.791106\n",
            "Gradient Boosting - PCA@0.90    0.791834   0.792271  0.791834  0.791713\n",
            "XGBoost - PCA@1.0               0.799310   0.799645  0.799310  0.799285\n",
            "XGBoost - PCA@0.95              0.810236   0.810367  0.810236  0.810233\n",
            "XGBoost - PCA@0.90              0.804485   0.804588  0.804485  0.804484\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# 4. Log results\n",
        "# ==============================\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
